{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "Homework10-11.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H6gLih9vve1"
      },
      "source": [
        "# Homework Session 11 Neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OtvCQeDvve8"
      },
      "source": [
        "## Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZPdvqVhvve9"
      },
      "source": [
        "The purpose of the below is to classify days over years 2017-2018 by their corresponding mobility patterns between 10 zones in Taipei (quantified by an aggregated temporal network of subway ridership flows across the city)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA_gD26Dvve9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K0a-xW8vve-"
      },
      "source": [
        "#read the data\n",
        "TNet=pd.read_csv('https://raw.githubusercontent.com/CUSP2021ADS/Data/main/taipeiD_TNet2.csv',header=None);"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "dlwvHeYuvve-",
        "outputId": "b3d995a2-1a79-45b9-8fa2-458d15d5a9f4"
      },
      "source": [
        "TNet.head() \n",
        "#each row represents a 10x10 adjacency matrix of the normalized Taipei subway mobility network between 10 zones flattened into a 100x1 row corresponding to a single day\n",
        "#days start at jan-1-2017"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.003590</td>\n",
              "      <td>0.008316</td>\n",
              "      <td>0.007859</td>\n",
              "      <td>0.012942</td>\n",
              "      <td>0.012196</td>\n",
              "      <td>0.019543</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.003327</td>\n",
              "      <td>0.004588</td>\n",
              "      <td>0.016362</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.006420</td>\n",
              "      <td>0.009864</td>\n",
              "      <td>0.005530</td>\n",
              "      <td>0.007357</td>\n",
              "      <td>0.017389</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>0.001672</td>\n",
              "      <td>0.002640</td>\n",
              "      <td>0.002878</td>\n",
              "      <td>0.003133</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.003610</td>\n",
              "      <td>0.001157</td>\n",
              "      <td>0.002406</td>\n",
              "      <td>0.004315</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>0.001456</td>\n",
              "      <td>0.008631</td>\n",
              "      <td>0.007123</td>\n",
              "      <td>0.002301</td>\n",
              "      <td>0.010586</td>\n",
              "      <td>0.007468</td>\n",
              "      <td>0.010193</td>\n",
              "      <td>0.010568</td>\n",
              "      <td>0.020925</td>\n",
              "      <td>0.001346</td>\n",
              "      <td>0.002716</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010876</td>\n",
              "      <td>0.007325</td>\n",
              "      <td>0.002859</td>\n",
              "      <td>0.009160</td>\n",
              "      <td>0.013417</td>\n",
              "      <td>0.009071</td>\n",
              "      <td>0.050107</td>\n",
              "      <td>0.043340</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>0.003823</td>\n",
              "      <td>0.013696</td>\n",
              "      <td>0.014299</td>\n",
              "      <td>0.005237</td>\n",
              "      <td>0.015900</td>\n",
              "      <td>0.025870</td>\n",
              "      <td>0.021652</td>\n",
              "      <td>0.035190</td>\n",
              "      <td>0.049923</td>\n",
              "      <td>0.002971</td>\n",
              "      <td>0.009171</td>\n",
              "      <td>0.001081</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.001091</td>\n",
              "      <td>0.003131</td>\n",
              "      <td>0.008141</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.004099</td>\n",
              "      <td>0.009125</td>\n",
              "      <td>0.005163</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.001533</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.005408</td>\n",
              "      <td>0.008922</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.011075</td>\n",
              "      <td>0.005073</td>\n",
              "      <td>0.012708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.021283</td>\n",
              "      <td>0.005215</td>\n",
              "      <td>0.003530</td>\n",
              "      <td>0.009359</td>\n",
              "      <td>0.007803</td>\n",
              "      <td>0.014288</td>\n",
              "      <td>0.011185</td>\n",
              "      <td>0.019044</td>\n",
              "      <td>0.001382</td>\n",
              "      <td>0.003499</td>\n",
              "      <td>0.004859</td>\n",
              "      <td>0.016886</td>\n",
              "      <td>0.003053</td>\n",
              "      <td>0.007339</td>\n",
              "      <td>0.009820</td>\n",
              "      <td>0.005745</td>\n",
              "      <td>0.006608</td>\n",
              "      <td>0.016490</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>0.001866</td>\n",
              "      <td>0.002897</td>\n",
              "      <td>0.002929</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.003471</td>\n",
              "      <td>0.001210</td>\n",
              "      <td>0.002197</td>\n",
              "      <td>0.004039</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>0.009672</td>\n",
              "      <td>0.007348</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>0.012551</td>\n",
              "      <td>0.007475</td>\n",
              "      <td>0.011087</td>\n",
              "      <td>0.009090</td>\n",
              "      <td>0.020644</td>\n",
              "      <td>0.001560</td>\n",
              "      <td>0.003032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010139</td>\n",
              "      <td>0.006609</td>\n",
              "      <td>0.002760</td>\n",
              "      <td>0.008469</td>\n",
              "      <td>0.010956</td>\n",
              "      <td>0.009114</td>\n",
              "      <td>0.046897</td>\n",
              "      <td>0.038464</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>0.003762</td>\n",
              "      <td>0.014380</td>\n",
              "      <td>0.016011</td>\n",
              "      <td>0.003765</td>\n",
              "      <td>0.017911</td>\n",
              "      <td>0.022929</td>\n",
              "      <td>0.021901</td>\n",
              "      <td>0.034270</td>\n",
              "      <td>0.040281</td>\n",
              "      <td>0.003776</td>\n",
              "      <td>0.009128</td>\n",
              "      <td>0.001298</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>0.001337</td>\n",
              "      <td>0.003490</td>\n",
              "      <td>0.008978</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>0.004377</td>\n",
              "      <td>0.010360</td>\n",
              "      <td>0.005964</td>\n",
              "      <td>0.002803</td>\n",
              "      <td>0.001757</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>0.005515</td>\n",
              "      <td>0.009650</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>0.009618</td>\n",
              "      <td>0.005946</td>\n",
              "      <td>0.013709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.028988</td>\n",
              "      <td>0.006511</td>\n",
              "      <td>0.005591</td>\n",
              "      <td>0.012970</td>\n",
              "      <td>0.007816</td>\n",
              "      <td>0.015878</td>\n",
              "      <td>0.010973</td>\n",
              "      <td>0.015768</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.005388</td>\n",
              "      <td>0.006879</td>\n",
              "      <td>0.013790</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>0.009401</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.006937</td>\n",
              "      <td>0.013613</td>\n",
              "      <td>0.001545</td>\n",
              "      <td>0.002790</td>\n",
              "      <td>0.005575</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>0.004373</td>\n",
              "      <td>0.003305</td>\n",
              "      <td>0.005246</td>\n",
              "      <td>0.001148</td>\n",
              "      <td>0.002829</td>\n",
              "      <td>0.003980</td>\n",
              "      <td>0.000803</td>\n",
              "      <td>0.002643</td>\n",
              "      <td>0.013623</td>\n",
              "      <td>0.008729</td>\n",
              "      <td>0.003722</td>\n",
              "      <td>0.015259</td>\n",
              "      <td>0.006972</td>\n",
              "      <td>0.012822</td>\n",
              "      <td>0.009648</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>0.002672</td>\n",
              "      <td>0.004533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011613</td>\n",
              "      <td>0.007232</td>\n",
              "      <td>0.003313</td>\n",
              "      <td>0.009770</td>\n",
              "      <td>0.008924</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.039863</td>\n",
              "      <td>0.029368</td>\n",
              "      <td>0.000581</td>\n",
              "      <td>0.005011</td>\n",
              "      <td>0.013882</td>\n",
              "      <td>0.013373</td>\n",
              "      <td>0.003620</td>\n",
              "      <td>0.017100</td>\n",
              "      <td>0.018839</td>\n",
              "      <td>0.018666</td>\n",
              "      <td>0.026413</td>\n",
              "      <td>0.030177</td>\n",
              "      <td>0.003673</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.002030</td>\n",
              "      <td>0.001531</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>0.002192</td>\n",
              "      <td>0.004388</td>\n",
              "      <td>0.010398</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.004129</td>\n",
              "      <td>0.011692</td>\n",
              "      <td>0.009807</td>\n",
              "      <td>0.004649</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>0.002672</td>\n",
              "      <td>0.004291</td>\n",
              "      <td>0.007385</td>\n",
              "      <td>0.009558</td>\n",
              "      <td>0.004293</td>\n",
              "      <td>0.008791</td>\n",
              "      <td>0.010040</td>\n",
              "      <td>0.016301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.029534</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>0.005615</td>\n",
              "      <td>0.013017</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.016098</td>\n",
              "      <td>0.011182</td>\n",
              "      <td>0.015815</td>\n",
              "      <td>0.002325</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>0.006955</td>\n",
              "      <td>0.014044</td>\n",
              "      <td>0.003699</td>\n",
              "      <td>0.009330</td>\n",
              "      <td>0.008967</td>\n",
              "      <td>0.006290</td>\n",
              "      <td>0.007313</td>\n",
              "      <td>0.013566</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.002833</td>\n",
              "      <td>0.005504</td>\n",
              "      <td>0.003456</td>\n",
              "      <td>0.004210</td>\n",
              "      <td>0.003239</td>\n",
              "      <td>0.005267</td>\n",
              "      <td>0.001098</td>\n",
              "      <td>0.002910</td>\n",
              "      <td>0.003914</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>0.013751</td>\n",
              "      <td>0.008552</td>\n",
              "      <td>0.003736</td>\n",
              "      <td>0.014924</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.012755</td>\n",
              "      <td>0.009960</td>\n",
              "      <td>0.017484</td>\n",
              "      <td>0.002665</td>\n",
              "      <td>0.004498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011870</td>\n",
              "      <td>0.007473</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>0.010152</td>\n",
              "      <td>0.009209</td>\n",
              "      <td>0.009930</td>\n",
              "      <td>0.041379</td>\n",
              "      <td>0.029797</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>0.005187</td>\n",
              "      <td>0.013526</td>\n",
              "      <td>0.012225</td>\n",
              "      <td>0.003561</td>\n",
              "      <td>0.016417</td>\n",
              "      <td>0.018527</td>\n",
              "      <td>0.017725</td>\n",
              "      <td>0.025343</td>\n",
              "      <td>0.030699</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>0.007993</td>\n",
              "      <td>0.002014</td>\n",
              "      <td>0.001469</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>0.002228</td>\n",
              "      <td>0.004599</td>\n",
              "      <td>0.010936</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>0.004077</td>\n",
              "      <td>0.012252</td>\n",
              "      <td>0.009988</td>\n",
              "      <td>0.004611</td>\n",
              "      <td>0.002473</td>\n",
              "      <td>0.002636</td>\n",
              "      <td>0.004195</td>\n",
              "      <td>0.007255</td>\n",
              "      <td>0.009487</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>0.008729</td>\n",
              "      <td>0.010296</td>\n",
              "      <td>0.016437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.029333</td>\n",
              "      <td>0.006525</td>\n",
              "      <td>0.005727</td>\n",
              "      <td>0.013098</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.016358</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.015677</td>\n",
              "      <td>0.002344</td>\n",
              "      <td>0.005527</td>\n",
              "      <td>0.006860</td>\n",
              "      <td>0.013586</td>\n",
              "      <td>0.003710</td>\n",
              "      <td>0.009243</td>\n",
              "      <td>0.008994</td>\n",
              "      <td>0.006580</td>\n",
              "      <td>0.007113</td>\n",
              "      <td>0.014127</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.005472</td>\n",
              "      <td>0.003366</td>\n",
              "      <td>0.004166</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.005255</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>0.002889</td>\n",
              "      <td>0.003851</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.002525</td>\n",
              "      <td>0.013695</td>\n",
              "      <td>0.008369</td>\n",
              "      <td>0.003819</td>\n",
              "      <td>0.015103</td>\n",
              "      <td>0.006924</td>\n",
              "      <td>0.012921</td>\n",
              "      <td>0.009824</td>\n",
              "      <td>0.017778</td>\n",
              "      <td>0.002605</td>\n",
              "      <td>0.004648</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011968</td>\n",
              "      <td>0.007428</td>\n",
              "      <td>0.003594</td>\n",
              "      <td>0.010037</td>\n",
              "      <td>0.009058</td>\n",
              "      <td>0.009952</td>\n",
              "      <td>0.040614</td>\n",
              "      <td>0.030371</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.005188</td>\n",
              "      <td>0.013355</td>\n",
              "      <td>0.011994</td>\n",
              "      <td>0.003674</td>\n",
              "      <td>0.016204</td>\n",
              "      <td>0.018132</td>\n",
              "      <td>0.017880</td>\n",
              "      <td>0.025106</td>\n",
              "      <td>0.030883</td>\n",
              "      <td>0.003316</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.002130</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.002186</td>\n",
              "      <td>0.004413</td>\n",
              "      <td>0.010712</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.004160</td>\n",
              "      <td>0.011789</td>\n",
              "      <td>0.009981</td>\n",
              "      <td>0.004694</td>\n",
              "      <td>0.002515</td>\n",
              "      <td>0.002677</td>\n",
              "      <td>0.004222</td>\n",
              "      <td>0.007269</td>\n",
              "      <td>0.009921</td>\n",
              "      <td>0.004387</td>\n",
              "      <td>0.008923</td>\n",
              "      <td>0.010381</td>\n",
              "      <td>0.016914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        97        98        99\n",
              "0  0.017943  0.005415  0.003590  ...  0.011075  0.005073  0.012708\n",
              "1  0.021283  0.005215  0.003530  ...  0.009618  0.005946  0.013709\n",
              "2  0.028988  0.006511  0.005591  ...  0.008791  0.010040  0.016301\n",
              "3  0.029534  0.006471  0.005615  ...  0.008729  0.010296  0.016437\n",
              "4  0.029333  0.006525  0.005727  ...  0.008923  0.010381  0.016914\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pgn8xubvve_"
      },
      "source": [
        "#convert to an array and scale the data\n",
        "X=np.array(TNet);"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD3ACyqtvvfA"
      },
      "source": [
        "X=MinMaxScaler(feature_range=(0, 1), copy=True).fit_transform(X)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1GMhHMlvvfA",
        "outputId": "4a0a179b-dda6-4efc-bd96-f5540aec43e1"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(669, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMOwI-dCvvfA",
        "outputId": "0254df82-583b-4e26-dc0d-3c18227ac6a9"
      },
      "source": [
        "#define day of the week corresponding to each day of observation; 0-Sunday, 1-Monday,...,6-Saturday\n",
        "y=np.array(range(669))%7; y[:10]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwqfK7K9vvfB",
        "outputId": "beae7938-b294-4552-a197-9d6f068dd33d"
      },
      "source": [
        "yc=np_utils.to_categorical(y) #get categorical binary variables isSunday, isMonday,...\n",
        "yc[:5]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILN4VhLNvvfB",
        "outputId": "1adbb35b-632a-42cc-8e80-8e7bd855301d"
      },
      "source": [
        "X_test=X[400:,:]; X_train=X[:400,:]; #split the data into training and test\n",
        "y_test=yb[400:]; y_train=yb[:400]\n",
        "y_test"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXRxoArOvvfC"
      },
      "source": [
        "## Task 1. Classify weekdays/weekends\n",
        "Label the rows with ones for weekends, zeros for weekdays.\n",
        "Train a neural network with 4 layers of 30,10,3 and 1 (output) neurons over the training sample against this label, evaluating its performance over the test sample. Report the acheived accuracy (categorical) over the test sample\n",
        "\n",
        "First three layers use relu activation function, last one - sigmoid.\n",
        "Use loss='binary_crossentropy', optimizer='adam', 100 epochs, batch_size=20. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9W6b3l9JJlh",
        "outputId": "613e36e1-b8a8-49ea-ab07-f2970db8fd71"
      },
      "source": [
        "# convert to ones for weekends 0 for weekdays\n",
        "\n",
        "\n",
        "\n",
        "yb =np.array([1 if i%7 == 0 or i%7 == 6 else 0 for i in range(669)]); yb[:10]\n",
        "\n",
        "yb[:10]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 1, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqrOzt94wGWC",
        "outputId": "0f9eeb1c-d0c1-4139-adf1-663fce2280f2"
      },
      "source": [
        "np.random.seed(2019)\n",
        "dim = X_train.shape[1]\n",
        "test = y_test\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='relu', input_dim=dim))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=20, verbose=2)\n",
        "print(accuracy_score(y_test, model.predict_classes(X_test)))\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 - 1s - loss: 0.7062 - categorical_accuracy: 1.0000 - val_loss: 0.6536 - val_categorical_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "20/20 - 0s - loss: 0.6383 - categorical_accuracy: 1.0000 - val_loss: 0.6214 - val_categorical_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "20/20 - 0s - loss: 0.6090 - categorical_accuracy: 1.0000 - val_loss: 0.5927 - val_categorical_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "20/20 - 0s - loss: 0.5823 - categorical_accuracy: 1.0000 - val_loss: 0.5615 - val_categorical_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "20/20 - 0s - loss: 0.5533 - categorical_accuracy: 1.0000 - val_loss: 0.5460 - val_categorical_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "20/20 - 0s - loss: 0.5414 - categorical_accuracy: 1.0000 - val_loss: 0.5355 - val_categorical_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "20/20 - 0s - loss: 0.5308 - categorical_accuracy: 1.0000 - val_loss: 0.5250 - val_categorical_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "20/20 - 0s - loss: 0.5204 - categorical_accuracy: 1.0000 - val_loss: 0.5165 - val_categorical_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "20/20 - 0s - loss: 0.5107 - categorical_accuracy: 1.0000 - val_loss: 0.5081 - val_categorical_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "20/20 - 0s - loss: 0.5021 - categorical_accuracy: 1.0000 - val_loss: 0.4985 - val_categorical_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "20/20 - 0s - loss: 0.4907 - categorical_accuracy: 1.0000 - val_loss: 0.4890 - val_categorical_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "20/20 - 0s - loss: 0.4804 - categorical_accuracy: 1.0000 - val_loss: 0.4810 - val_categorical_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "20/20 - 0s - loss: 0.4733 - categorical_accuracy: 1.0000 - val_loss: 0.4731 - val_categorical_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "20/20 - 0s - loss: 0.4648 - categorical_accuracy: 1.0000 - val_loss: 0.4650 - val_categorical_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "20/20 - 0s - loss: 0.4526 - categorical_accuracy: 1.0000 - val_loss: 0.4566 - val_categorical_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "20/20 - 0s - loss: 0.4475 - categorical_accuracy: 1.0000 - val_loss: 0.4498 - val_categorical_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "20/20 - 0s - loss: 0.4386 - categorical_accuracy: 1.0000 - val_loss: 0.4468 - val_categorical_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "20/20 - 0s - loss: 0.4305 - categorical_accuracy: 1.0000 - val_loss: 0.4349 - val_categorical_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "20/20 - 0s - loss: 0.4221 - categorical_accuracy: 1.0000 - val_loss: 0.4325 - val_categorical_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "20/20 - 0s - loss: 0.4150 - categorical_accuracy: 1.0000 - val_loss: 0.4225 - val_categorical_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "20/20 - 0s - loss: 0.4050 - categorical_accuracy: 1.0000 - val_loss: 0.4216 - val_categorical_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "20/20 - 0s - loss: 0.3992 - categorical_accuracy: 1.0000 - val_loss: 0.4132 - val_categorical_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "20/20 - 0s - loss: 0.3979 - categorical_accuracy: 1.0000 - val_loss: 0.4099 - val_categorical_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "20/20 - 0s - loss: 0.3879 - categorical_accuracy: 1.0000 - val_loss: 0.4004 - val_categorical_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "20/20 - 0s - loss: 0.3792 - categorical_accuracy: 1.0000 - val_loss: 0.3943 - val_categorical_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "20/20 - 0s - loss: 0.3731 - categorical_accuracy: 1.0000 - val_loss: 0.3911 - val_categorical_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "20/20 - 0s - loss: 0.3701 - categorical_accuracy: 1.0000 - val_loss: 0.3838 - val_categorical_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "20/20 - 0s - loss: 0.3618 - categorical_accuracy: 1.0000 - val_loss: 0.3784 - val_categorical_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "20/20 - 0s - loss: 0.3583 - categorical_accuracy: 1.0000 - val_loss: 0.3750 - val_categorical_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "20/20 - 0s - loss: 0.3512 - categorical_accuracy: 1.0000 - val_loss: 0.3730 - val_categorical_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "20/20 - 0s - loss: 0.3488 - categorical_accuracy: 1.0000 - val_loss: 0.3653 - val_categorical_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "20/20 - 0s - loss: 0.3414 - categorical_accuracy: 1.0000 - val_loss: 0.3595 - val_categorical_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "20/20 - 0s - loss: 0.3350 - categorical_accuracy: 1.0000 - val_loss: 0.3548 - val_categorical_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "20/20 - 0s - loss: 0.3294 - categorical_accuracy: 1.0000 - val_loss: 0.3535 - val_categorical_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "20/20 - 0s - loss: 0.3269 - categorical_accuracy: 1.0000 - val_loss: 0.3459 - val_categorical_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "20/20 - 0s - loss: 0.3223 - categorical_accuracy: 1.0000 - val_loss: 0.3426 - val_categorical_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "20/20 - 0s - loss: 0.3218 - categorical_accuracy: 1.0000 - val_loss: 0.3410 - val_categorical_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "20/20 - 0s - loss: 0.3149 - categorical_accuracy: 1.0000 - val_loss: 0.3380 - val_categorical_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "20/20 - 0s - loss: 0.3092 - categorical_accuracy: 1.0000 - val_loss: 0.3328 - val_categorical_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "20/20 - 0s - loss: 0.3075 - categorical_accuracy: 1.0000 - val_loss: 0.3285 - val_categorical_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "20/20 - 0s - loss: 0.2988 - categorical_accuracy: 1.0000 - val_loss: 0.3240 - val_categorical_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "20/20 - 0s - loss: 0.2940 - categorical_accuracy: 1.0000 - val_loss: 0.3179 - val_categorical_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "20/20 - 0s - loss: 0.2930 - categorical_accuracy: 1.0000 - val_loss: 0.3163 - val_categorical_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "20/20 - 0s - loss: 0.2875 - categorical_accuracy: 1.0000 - val_loss: 0.3135 - val_categorical_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "20/20 - 0s - loss: 0.2891 - categorical_accuracy: 1.0000 - val_loss: 0.3101 - val_categorical_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "20/20 - 0s - loss: 0.2812 - categorical_accuracy: 1.0000 - val_loss: 0.3047 - val_categorical_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "20/20 - 0s - loss: 0.2794 - categorical_accuracy: 1.0000 - val_loss: 0.3059 - val_categorical_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "20/20 - 0s - loss: 0.2750 - categorical_accuracy: 1.0000 - val_loss: 0.2966 - val_categorical_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "20/20 - 0s - loss: 0.2684 - categorical_accuracy: 1.0000 - val_loss: 0.2935 - val_categorical_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "20/20 - 0s - loss: 0.2651 - categorical_accuracy: 1.0000 - val_loss: 0.2950 - val_categorical_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "20/20 - 0s - loss: 0.2603 - categorical_accuracy: 1.0000 - val_loss: 0.2898 - val_categorical_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "20/20 - 0s - loss: 0.2584 - categorical_accuracy: 1.0000 - val_loss: 0.2874 - val_categorical_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "20/20 - 0s - loss: 0.2519 - categorical_accuracy: 1.0000 - val_loss: 0.2817 - val_categorical_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "20/20 - 0s - loss: 0.2504 - categorical_accuracy: 1.0000 - val_loss: 0.2800 - val_categorical_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "20/20 - 0s - loss: 0.2464 - categorical_accuracy: 1.0000 - val_loss: 0.2816 - val_categorical_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "20/20 - 0s - loss: 0.2390 - categorical_accuracy: 1.0000 - val_loss: 0.2699 - val_categorical_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "20/20 - 0s - loss: 0.2375 - categorical_accuracy: 1.0000 - val_loss: 0.2689 - val_categorical_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "20/20 - 0s - loss: 0.2338 - categorical_accuracy: 1.0000 - val_loss: 0.2656 - val_categorical_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "20/20 - 0s - loss: 0.2333 - categorical_accuracy: 1.0000 - val_loss: 0.2621 - val_categorical_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "20/20 - 0s - loss: 0.2289 - categorical_accuracy: 1.0000 - val_loss: 0.2592 - val_categorical_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "20/20 - 0s - loss: 0.2231 - categorical_accuracy: 1.0000 - val_loss: 0.2569 - val_categorical_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "20/20 - 0s - loss: 0.2242 - categorical_accuracy: 1.0000 - val_loss: 0.2680 - val_categorical_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "20/20 - 0s - loss: 0.2331 - categorical_accuracy: 1.0000 - val_loss: 0.2539 - val_categorical_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "20/20 - 0s - loss: 0.2215 - categorical_accuracy: 1.0000 - val_loss: 0.2516 - val_categorical_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "20/20 - 0s - loss: 0.2125 - categorical_accuracy: 1.0000 - val_loss: 0.2486 - val_categorical_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "20/20 - 0s - loss: 0.2080 - categorical_accuracy: 1.0000 - val_loss: 0.2475 - val_categorical_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "20/20 - 0s - loss: 0.2058 - categorical_accuracy: 1.0000 - val_loss: 0.2483 - val_categorical_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "20/20 - 0s - loss: 0.2076 - categorical_accuracy: 1.0000 - val_loss: 0.2442 - val_categorical_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "20/20 - 0s - loss: 0.1999 - categorical_accuracy: 1.0000 - val_loss: 0.2444 - val_categorical_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "20/20 - 0s - loss: 0.1975 - categorical_accuracy: 1.0000 - val_loss: 0.2437 - val_categorical_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "20/20 - 0s - loss: 0.1953 - categorical_accuracy: 1.0000 - val_loss: 0.2323 - val_categorical_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "20/20 - 0s - loss: 0.1928 - categorical_accuracy: 1.0000 - val_loss: 0.2312 - val_categorical_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "20/20 - 0s - loss: 0.1914 - categorical_accuracy: 1.0000 - val_loss: 0.2328 - val_categorical_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "20/20 - 0s - loss: 0.1859 - categorical_accuracy: 1.0000 - val_loss: 0.2252 - val_categorical_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "20/20 - 0s - loss: 0.1836 - categorical_accuracy: 1.0000 - val_loss: 0.2314 - val_categorical_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "20/20 - 0s - loss: 0.1807 - categorical_accuracy: 1.0000 - val_loss: 0.2229 - val_categorical_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "20/20 - 0s - loss: 0.1781 - categorical_accuracy: 1.0000 - val_loss: 0.2293 - val_categorical_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "20/20 - 0s - loss: 0.1781 - categorical_accuracy: 1.0000 - val_loss: 0.2272 - val_categorical_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "20/20 - 0s - loss: 0.1738 - categorical_accuracy: 1.0000 - val_loss: 0.2194 - val_categorical_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "20/20 - 0s - loss: 0.1725 - categorical_accuracy: 1.0000 - val_loss: 0.2241 - val_categorical_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "20/20 - 0s - loss: 0.1704 - categorical_accuracy: 1.0000 - val_loss: 0.2238 - val_categorical_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "20/20 - 0s - loss: 0.1683 - categorical_accuracy: 1.0000 - val_loss: 0.2137 - val_categorical_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "20/20 - 0s - loss: 0.1656 - categorical_accuracy: 1.0000 - val_loss: 0.2071 - val_categorical_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "20/20 - 0s - loss: 0.1642 - categorical_accuracy: 1.0000 - val_loss: 0.2232 - val_categorical_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "20/20 - 0s - loss: 0.1634 - categorical_accuracy: 1.0000 - val_loss: 0.2255 - val_categorical_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "20/20 - 0s - loss: 0.1616 - categorical_accuracy: 1.0000 - val_loss: 0.2067 - val_categorical_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "20/20 - 0s - loss: 0.1595 - categorical_accuracy: 1.0000 - val_loss: 0.2238 - val_categorical_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "20/20 - 0s - loss: 0.1545 - categorical_accuracy: 1.0000 - val_loss: 0.2022 - val_categorical_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "20/20 - 0s - loss: 0.1525 - categorical_accuracy: 1.0000 - val_loss: 0.1990 - val_categorical_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "20/20 - 0s - loss: 0.1524 - categorical_accuracy: 1.0000 - val_loss: 0.1950 - val_categorical_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "20/20 - 0s - loss: 0.1517 - categorical_accuracy: 1.0000 - val_loss: 0.2199 - val_categorical_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "20/20 - 0s - loss: 0.1486 - categorical_accuracy: 1.0000 - val_loss: 0.2005 - val_categorical_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "20/20 - 0s - loss: 0.1466 - categorical_accuracy: 1.0000 - val_loss: 0.1962 - val_categorical_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "20/20 - 0s - loss: 0.1444 - categorical_accuracy: 1.0000 - val_loss: 0.1977 - val_categorical_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "20/20 - 0s - loss: 0.1410 - categorical_accuracy: 1.0000 - val_loss: 0.1942 - val_categorical_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "20/20 - 0s - loss: 0.1390 - categorical_accuracy: 1.0000 - val_loss: 0.2067 - val_categorical_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "20/20 - 0s - loss: 0.1397 - categorical_accuracy: 1.0000 - val_loss: 0.1890 - val_categorical_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "20/20 - 0s - loss: 0.1363 - categorical_accuracy: 1.0000 - val_loss: 0.1926 - val_categorical_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "20/20 - 0s - loss: 0.1345 - categorical_accuracy: 1.0000 - val_loss: 0.1863 - val_categorical_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "20/20 - 0s - loss: 0.1329 - categorical_accuracy: 1.0000 - val_loss: 0.1869 - val_categorical_accuracy: 1.0000\n",
            "0.9776951672862454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQznBJxMvvfC"
      },
      "source": [
        "## Task 2. Classify all days of the week\n",
        "Train a neural network against the origial categorical label. Use 5 layers of 40,15,5 and 7 (outputs, representing probabilities for a current input to correspond to each of the weekdays) neurons over the training sample, evaluating its performance over the test sample (use 'categorical_accurary'). Report the acheived accuracy (categorical) over the test sample.\n",
        "\n",
        "First three layers use relu activation function, last one - sigmoid.\n",
        "Use loss='binary_crossentropy', optimizer='adam', 200 epochs, batch_size=20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSdyxZY0oD5k",
        "outputId": "163bd8a0-1801-4579-c3e6-d57747e67e27"
      },
      "source": [
        "y_test=yc[400:,:]; y_train=yc[:400,:]\n",
        "y_test\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k9dDKexk_UCD",
        "outputId": "0f80177f-06ee-419f-c771-b9b78f57e847"
      },
      "source": [
        "np.random.seed(2019)\n",
        "dim = X_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(40, activation='relu', input_dim=dim))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(7, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=20, verbose=2)\n",
        "print(accuracy_score(y_test, model.predict_classes(X_test)))\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-149a9abfa996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1608 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4979 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:174 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((20, 1) vs (20, 7))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3r3CT5vvfC"
      },
      "source": [
        "## part 2\n",
        "\n",
        "Use the same datasets as in the Advanced NN lab and further train NN with different architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ng85C_vvfD"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Try the facial recognition task from NN lab 2 with different model specifications and report model accuracy:\n",
        "1. Try different dropouts - 0.2, 0.3, 0.4\n",
        "2. Try different convolution windows: (3$\\times$3, 10$\\times$10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVU2zRBMvvfD",
        "outputId": "57b8b0a5-eb20-46e9-b7a5-fa32f4eca4c0"
      },
      "source": [
        "# load the data\n",
        "\n",
        "from sklearn.datasets import fetch_lfw_people \n",
        "from keras.datasets import mnist\n",
        "\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person = 70, resize = 0.4) \n",
        "  \n",
        "# the images arrays to find the shapes (for plotting) \n",
        "n_samples, h, w = lfw_people.images.shape \n",
        "  \n",
        "# Instead of providing 2D data, X has data already in the form  of a vector that \n",
        "# is required in this approach. \n",
        "X = lfw_people.data \n",
        "n_features = X.shape[1] \n",
        "\n",
        "y = lfw_people.target \n",
        "target_names = lfw_people.target_names \n",
        "n_classes = target_names.shape[0] "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976012\n",
            "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976009\n",
            "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976006\n",
            "Downloading LFW data (~200MB): https://ndownloader.figshare.com/files/5976015\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0KWfHqQOLkh"
      },
      "source": [
        "# lets split and reform the dataset in the format compatible for CNN\n",
        "# basically we are restructuring the data into grid shapes which are apt for convolutions and further steps\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( \n",
        "    X, y, test_size = 0.2)\n",
        "\n",
        "X_train_pp = (X_train.reshape(X_train.shape[0], 50, 37, 1).astype('float32')) / 255 # normalize\n",
        "X_test_pp = (X_test.reshape(X_test.shape[0], 50, 37, 1).astype('float32')) / 255\n",
        "\n",
        "y_train_pp = np_utils.to_categorical(y_train)\n",
        "y_test_pp = np_utils.to_categorical(y_test)\n",
        "\n",
        "num_classes = y_train_pp.shape[1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2IaRJhHOUVF",
        "outputId": "147e0470-aef9-41f1-8e3b-01c0af77c334"
      },
      "source": [
        "\n",
        "# model dropout .2\n",
        "\n",
        "np.random.seed(2002)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile, fit, and generate scores and predicted probabilities.\n",
        "# should take under 2-3 minutes to train\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_pp, y_train_pp, validation_data=(X_test_pp, y_test_pp), epochs=50, batch_size=200, verbose=2)\n",
        "scores = model.evaluate(X_test_pp, y_test_pp, verbose=0)\n",
        "prob = model.predict(X_test_pp)\n",
        "\n",
        "accuracy_score(y_test, model.predict_classes(X_test_pp))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 - 4s - loss: 1.7676 - accuracy: 0.3641 - val_loss: 1.6411 - val_accuracy: 0.4380\n",
            "Epoch 2/50\n",
            "6/6 - 3s - loss: 1.6728 - accuracy: 0.4049 - val_loss: 1.5984 - val_accuracy: 0.4380\n",
            "Epoch 3/50\n",
            "6/6 - 3s - loss: 1.6131 - accuracy: 0.4087 - val_loss: 1.5590 - val_accuracy: 0.5078\n",
            "Epoch 4/50\n",
            "6/6 - 3s - loss: 1.5440 - accuracy: 0.4447 - val_loss: 1.5209 - val_accuracy: 0.4651\n",
            "Epoch 5/50\n",
            "6/6 - 3s - loss: 1.4226 - accuracy: 0.4951 - val_loss: 1.4103 - val_accuracy: 0.5116\n",
            "Epoch 6/50\n",
            "6/6 - 3s - loss: 1.3346 - accuracy: 0.5340 - val_loss: 1.3610 - val_accuracy: 0.5504\n",
            "Epoch 7/50\n",
            "6/6 - 3s - loss: 1.2524 - accuracy: 0.5291 - val_loss: 1.2248 - val_accuracy: 0.5853\n",
            "Epoch 8/50\n",
            "6/6 - 3s - loss: 1.0877 - accuracy: 0.5942 - val_loss: 1.1928 - val_accuracy: 0.6047\n",
            "Epoch 9/50\n",
            "6/6 - 3s - loss: 1.0019 - accuracy: 0.6583 - val_loss: 1.0834 - val_accuracy: 0.6318\n",
            "Epoch 10/50\n",
            "6/6 - 3s - loss: 0.8511 - accuracy: 0.7388 - val_loss: 1.0250 - val_accuracy: 0.6705\n",
            "Epoch 11/50\n",
            "6/6 - 3s - loss: 0.8093 - accuracy: 0.7524 - val_loss: 0.9399 - val_accuracy: 0.6977\n",
            "Epoch 12/50\n",
            "6/6 - 3s - loss: 0.7224 - accuracy: 0.7544 - val_loss: 0.8609 - val_accuracy: 0.7287\n",
            "Epoch 13/50\n",
            "6/6 - 3s - loss: 0.6262 - accuracy: 0.7883 - val_loss: 0.9800 - val_accuracy: 0.6744\n",
            "Epoch 14/50\n",
            "6/6 - 3s - loss: 0.6114 - accuracy: 0.7951 - val_loss: 0.8214 - val_accuracy: 0.7248\n",
            "Epoch 15/50\n",
            "6/6 - 3s - loss: 0.5419 - accuracy: 0.8388 - val_loss: 0.8312 - val_accuracy: 0.7287\n",
            "Epoch 16/50\n",
            "6/6 - 3s - loss: 0.5324 - accuracy: 0.8204 - val_loss: 0.7817 - val_accuracy: 0.7442\n",
            "Epoch 17/50\n",
            "6/6 - 3s - loss: 0.4604 - accuracy: 0.8553 - val_loss: 0.7599 - val_accuracy: 0.7752\n",
            "Epoch 18/50\n",
            "6/6 - 3s - loss: 0.4122 - accuracy: 0.8660 - val_loss: 0.7136 - val_accuracy: 0.7752\n",
            "Epoch 19/50\n",
            "6/6 - 3s - loss: 0.3665 - accuracy: 0.8825 - val_loss: 0.7230 - val_accuracy: 0.7868\n",
            "Epoch 20/50\n",
            "6/6 - 3s - loss: 0.3611 - accuracy: 0.8951 - val_loss: 0.6977 - val_accuracy: 0.8140\n",
            "Epoch 21/50\n",
            "6/6 - 3s - loss: 0.3205 - accuracy: 0.9107 - val_loss: 0.6613 - val_accuracy: 0.8062\n",
            "Epoch 22/50\n",
            "6/6 - 3s - loss: 0.2816 - accuracy: 0.9078 - val_loss: 0.6714 - val_accuracy: 0.7984\n",
            "Epoch 23/50\n",
            "6/6 - 3s - loss: 0.2775 - accuracy: 0.9214 - val_loss: 0.6784 - val_accuracy: 0.8140\n",
            "Epoch 24/50\n",
            "6/6 - 3s - loss: 0.2354 - accuracy: 0.9291 - val_loss: 0.6917 - val_accuracy: 0.8062\n",
            "Epoch 25/50\n",
            "6/6 - 3s - loss: 0.2116 - accuracy: 0.9320 - val_loss: 0.7012 - val_accuracy: 0.7984\n",
            "Epoch 26/50\n",
            "6/6 - 3s - loss: 0.2035 - accuracy: 0.9388 - val_loss: 0.6430 - val_accuracy: 0.8178\n",
            "Epoch 27/50\n",
            "6/6 - 3s - loss: 0.2016 - accuracy: 0.9379 - val_loss: 0.6539 - val_accuracy: 0.7984\n",
            "Epoch 28/50\n",
            "6/6 - 3s - loss: 0.1791 - accuracy: 0.9544 - val_loss: 0.6343 - val_accuracy: 0.8217\n",
            "Epoch 29/50\n",
            "6/6 - 3s - loss: 0.1411 - accuracy: 0.9612 - val_loss: 0.6585 - val_accuracy: 0.8411\n",
            "Epoch 30/50\n",
            "6/6 - 3s - loss: 0.1369 - accuracy: 0.9602 - val_loss: 0.6308 - val_accuracy: 0.8488\n",
            "Epoch 31/50\n",
            "6/6 - 3s - loss: 0.1250 - accuracy: 0.9718 - val_loss: 0.6446 - val_accuracy: 0.8140\n",
            "Epoch 32/50\n",
            "6/6 - 3s - loss: 0.1225 - accuracy: 0.9612 - val_loss: 0.5971 - val_accuracy: 0.8411\n",
            "Epoch 33/50\n",
            "6/6 - 3s - loss: 0.1087 - accuracy: 0.9786 - val_loss: 0.6772 - val_accuracy: 0.8140\n",
            "Epoch 34/50\n",
            "6/6 - 3s - loss: 0.0941 - accuracy: 0.9767 - val_loss: 0.6180 - val_accuracy: 0.8527\n",
            "Epoch 35/50\n",
            "6/6 - 3s - loss: 0.0896 - accuracy: 0.9825 - val_loss: 0.6032 - val_accuracy: 0.8488\n",
            "Epoch 36/50\n",
            "6/6 - 3s - loss: 0.0769 - accuracy: 0.9883 - val_loss: 0.6593 - val_accuracy: 0.8488\n",
            "Epoch 37/50\n",
            "6/6 - 3s - loss: 0.0690 - accuracy: 0.9845 - val_loss: 0.6621 - val_accuracy: 0.8605\n",
            "Epoch 38/50\n",
            "6/6 - 3s - loss: 0.0614 - accuracy: 0.9903 - val_loss: 0.6048 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "6/6 - 3s - loss: 0.0527 - accuracy: 0.9942 - val_loss: 0.6661 - val_accuracy: 0.8372\n",
            "Epoch 40/50\n",
            "6/6 - 3s - loss: 0.0883 - accuracy: 0.9709 - val_loss: 0.6499 - val_accuracy: 0.8527\n",
            "Epoch 41/50\n",
            "6/6 - 3s - loss: 0.0573 - accuracy: 0.9874 - val_loss: 0.6787 - val_accuracy: 0.8450\n",
            "Epoch 42/50\n",
            "6/6 - 3s - loss: 0.0636 - accuracy: 0.9864 - val_loss: 0.6611 - val_accuracy: 0.8527\n",
            "Epoch 43/50\n",
            "6/6 - 3s - loss: 0.0494 - accuracy: 0.9913 - val_loss: 0.7292 - val_accuracy: 0.8450\n",
            "Epoch 44/50\n",
            "6/6 - 3s - loss: 0.0520 - accuracy: 0.9883 - val_loss: 0.6894 - val_accuracy: 0.8450\n",
            "Epoch 45/50\n",
            "6/6 - 3s - loss: 0.0501 - accuracy: 0.9932 - val_loss: 0.6618 - val_accuracy: 0.8450\n",
            "Epoch 46/50\n",
            "6/6 - 3s - loss: 0.0488 - accuracy: 0.9903 - val_loss: 0.6779 - val_accuracy: 0.8372\n",
            "Epoch 47/50\n",
            "6/6 - 3s - loss: 0.0533 - accuracy: 0.9922 - val_loss: 0.7676 - val_accuracy: 0.8333\n",
            "Epoch 48/50\n",
            "6/6 - 3s - loss: 0.0462 - accuracy: 0.9903 - val_loss: 0.7049 - val_accuracy: 0.8527\n",
            "Epoch 49/50\n",
            "6/6 - 3s - loss: 0.0285 - accuracy: 0.9990 - val_loss: 0.7161 - val_accuracy: 0.8372\n",
            "Epoch 50/50\n",
            "6/6 - 3s - loss: 0.0305 - accuracy: 0.9990 - val_loss: 0.6617 - val_accuracy: 0.8566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8565891472868217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9FPVEdCOiNa",
        "outputId": "35dd6998-5cbe-4135-b11f-102f94c730c5"
      },
      "source": [
        "\n",
        "# model dropout .3\n",
        "\n",
        "np.random.seed(2002)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile, fit, and generate scores and predicted probabilities.\n",
        "# should take under 2-3 minutes to train\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_pp, y_train_pp, validation_data=(X_test_pp, y_test_pp), epochs=50, batch_size=200, verbose=2)\n",
        "scores = model.evaluate(X_test_pp, y_test_pp, verbose=0)\n",
        "prob = model.predict(X_test_pp)\n",
        "\n",
        "accuracy_score(y_test, model.predict_classes(X_test_pp))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 - 4s - loss: 1.7503 - accuracy: 0.3573 - val_loss: 1.6015 - val_accuracy: 0.4380\n",
            "Epoch 2/50\n",
            "6/6 - 3s - loss: 1.6589 - accuracy: 0.4049 - val_loss: 1.5661 - val_accuracy: 0.4380\n",
            "Epoch 3/50\n",
            "6/6 - 3s - loss: 1.6218 - accuracy: 0.4214 - val_loss: 1.5364 - val_accuracy: 0.4457\n",
            "Epoch 4/50\n",
            "6/6 - 3s - loss: 1.5392 - accuracy: 0.4670 - val_loss: 1.4676 - val_accuracy: 0.4845\n",
            "Epoch 5/50\n",
            "6/6 - 3s - loss: 1.4492 - accuracy: 0.4806 - val_loss: 1.4171 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "6/6 - 3s - loss: 1.3699 - accuracy: 0.5000 - val_loss: 1.3482 - val_accuracy: 0.5465\n",
            "Epoch 7/50\n",
            "6/6 - 3s - loss: 1.2660 - accuracy: 0.5359 - val_loss: 1.2769 - val_accuracy: 0.5698\n",
            "Epoch 8/50\n",
            "6/6 - 3s - loss: 1.1591 - accuracy: 0.5816 - val_loss: 1.2911 - val_accuracy: 0.5155\n",
            "Epoch 9/50\n",
            "6/6 - 3s - loss: 1.1151 - accuracy: 0.6068 - val_loss: 1.1968 - val_accuracy: 0.5891\n",
            "Epoch 10/50\n",
            "6/6 - 3s - loss: 1.0634 - accuracy: 0.6330 - val_loss: 1.1032 - val_accuracy: 0.6047\n",
            "Epoch 11/50\n",
            "6/6 - 3s - loss: 0.9967 - accuracy: 0.6573 - val_loss: 1.0470 - val_accuracy: 0.6589\n",
            "Epoch 12/50\n",
            "6/6 - 3s - loss: 0.8731 - accuracy: 0.7068 - val_loss: 0.9750 - val_accuracy: 0.6705\n",
            "Epoch 13/50\n",
            "6/6 - 3s - loss: 0.8117 - accuracy: 0.7291 - val_loss: 0.9372 - val_accuracy: 0.7054\n",
            "Epoch 14/50\n",
            "6/6 - 3s - loss: 0.7910 - accuracy: 0.7214 - val_loss: 0.9051 - val_accuracy: 0.7132\n",
            "Epoch 15/50\n",
            "6/6 - 3s - loss: 0.7072 - accuracy: 0.7689 - val_loss: 0.8597 - val_accuracy: 0.7248\n",
            "Epoch 16/50\n",
            "6/6 - 3s - loss: 0.6517 - accuracy: 0.7883 - val_loss: 0.8635 - val_accuracy: 0.7287\n",
            "Epoch 17/50\n",
            "6/6 - 3s - loss: 0.6272 - accuracy: 0.7845 - val_loss: 0.8291 - val_accuracy: 0.7326\n",
            "Epoch 18/50\n",
            "6/6 - 3s - loss: 0.6008 - accuracy: 0.8087 - val_loss: 0.8482 - val_accuracy: 0.7287\n",
            "Epoch 19/50\n",
            "6/6 - 3s - loss: 0.5585 - accuracy: 0.8272 - val_loss: 0.7954 - val_accuracy: 0.7752\n",
            "Epoch 20/50\n",
            "6/6 - 3s - loss: 0.5293 - accuracy: 0.8340 - val_loss: 0.8024 - val_accuracy: 0.7403\n",
            "Epoch 21/50\n",
            "6/6 - 3s - loss: 0.5186 - accuracy: 0.8359 - val_loss: 0.7473 - val_accuracy: 0.7674\n",
            "Epoch 22/50\n",
            "6/6 - 3s - loss: 0.4706 - accuracy: 0.8612 - val_loss: 0.7269 - val_accuracy: 0.7946\n",
            "Epoch 23/50\n",
            "6/6 - 3s - loss: 0.4339 - accuracy: 0.8689 - val_loss: 0.6889 - val_accuracy: 0.7907\n",
            "Epoch 24/50\n",
            "6/6 - 3s - loss: 0.4263 - accuracy: 0.8680 - val_loss: 0.6959 - val_accuracy: 0.7829\n",
            "Epoch 25/50\n",
            "6/6 - 3s - loss: 0.4015 - accuracy: 0.8786 - val_loss: 0.6546 - val_accuracy: 0.7946\n",
            "Epoch 26/50\n",
            "6/6 - 3s - loss: 0.3470 - accuracy: 0.8913 - val_loss: 0.6682 - val_accuracy: 0.7984\n",
            "Epoch 27/50\n",
            "6/6 - 3s - loss: 0.3442 - accuracy: 0.8932 - val_loss: 0.6917 - val_accuracy: 0.7791\n",
            "Epoch 28/50\n",
            "6/6 - 3s - loss: 0.3548 - accuracy: 0.8864 - val_loss: 0.6194 - val_accuracy: 0.8062\n",
            "Epoch 29/50\n",
            "6/6 - 3s - loss: 0.3146 - accuracy: 0.9165 - val_loss: 0.6129 - val_accuracy: 0.8295\n",
            "Epoch 30/50\n",
            "6/6 - 3s - loss: 0.2913 - accuracy: 0.9165 - val_loss: 0.6478 - val_accuracy: 0.7946\n",
            "Epoch 31/50\n",
            "6/6 - 3s - loss: 0.2706 - accuracy: 0.9165 - val_loss: 0.6619 - val_accuracy: 0.8217\n",
            "Epoch 32/50\n",
            "6/6 - 3s - loss: 0.2791 - accuracy: 0.9136 - val_loss: 0.6026 - val_accuracy: 0.8178\n",
            "Epoch 33/50\n",
            "6/6 - 3s - loss: 0.2832 - accuracy: 0.9049 - val_loss: 0.6083 - val_accuracy: 0.8217\n",
            "Epoch 34/50\n",
            "6/6 - 3s - loss: 0.2594 - accuracy: 0.9233 - val_loss: 0.6286 - val_accuracy: 0.8101\n",
            "Epoch 35/50\n",
            "6/6 - 3s - loss: 0.2138 - accuracy: 0.9388 - val_loss: 0.6309 - val_accuracy: 0.8217\n",
            "Epoch 36/50\n",
            "6/6 - 3s - loss: 0.1950 - accuracy: 0.9466 - val_loss: 0.5728 - val_accuracy: 0.8411\n",
            "Epoch 37/50\n",
            "6/6 - 3s - loss: 0.1760 - accuracy: 0.9573 - val_loss: 0.6054 - val_accuracy: 0.8295\n",
            "Epoch 38/50\n",
            "6/6 - 3s - loss: 0.1577 - accuracy: 0.9631 - val_loss: 0.6892 - val_accuracy: 0.8140\n",
            "Epoch 39/50\n",
            "6/6 - 3s - loss: 0.1767 - accuracy: 0.9427 - val_loss: 0.5943 - val_accuracy: 0.8372\n",
            "Epoch 40/50\n",
            "6/6 - 3s - loss: 0.1530 - accuracy: 0.9641 - val_loss: 0.5877 - val_accuracy: 0.8333\n",
            "Epoch 41/50\n",
            "6/6 - 3s - loss: 0.1477 - accuracy: 0.9583 - val_loss: 0.5579 - val_accuracy: 0.8643\n",
            "Epoch 42/50\n",
            "6/6 - 3s - loss: 0.1307 - accuracy: 0.9680 - val_loss: 0.5904 - val_accuracy: 0.8256\n",
            "Epoch 43/50\n",
            "6/6 - 3s - loss: 0.1216 - accuracy: 0.9670 - val_loss: 0.6257 - val_accuracy: 0.8488\n",
            "Epoch 44/50\n",
            "6/6 - 3s - loss: 0.1138 - accuracy: 0.9689 - val_loss: 0.5703 - val_accuracy: 0.8333\n",
            "Epoch 45/50\n",
            "6/6 - 3s - loss: 0.0996 - accuracy: 0.9796 - val_loss: 0.5867 - val_accuracy: 0.8488\n",
            "Epoch 46/50\n",
            "6/6 - 3s - loss: 0.0975 - accuracy: 0.9825 - val_loss: 0.5922 - val_accuracy: 0.8140\n",
            "Epoch 47/50\n",
            "6/6 - 3s - loss: 0.1006 - accuracy: 0.9786 - val_loss: 0.5815 - val_accuracy: 0.8450\n",
            "Epoch 48/50\n",
            "6/6 - 3s - loss: 0.0948 - accuracy: 0.9767 - val_loss: 0.6414 - val_accuracy: 0.8295\n",
            "Epoch 49/50\n",
            "6/6 - 3s - loss: 0.1037 - accuracy: 0.9699 - val_loss: 0.6148 - val_accuracy: 0.8295\n",
            "Epoch 50/50\n",
            "6/6 - 3s - loss: 0.0945 - accuracy: 0.9796 - val_loss: 0.5911 - val_accuracy: 0.8372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8372093023255814"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3EwG_tgOsxp",
        "outputId": "b59ee3fc-151a-45d3-d2c0-22fe9fc02ac6"
      },
      "source": [
        "\n",
        "# model dropout .4\n",
        "\n",
        "np.random.seed(2002)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile, fit, and generate scores and predicted probabilities.\n",
        "# should take under 2-3 minutes to train\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_pp, y_train_pp, validation_data=(X_test_pp, y_test_pp), epochs=50, batch_size=200, verbose=2)\n",
        "scores = model.evaluate(X_test_pp, y_test_pp, verbose=0)\n",
        "prob = model.predict(X_test_pp)\n",
        "\n",
        "accuracy_score(y_test, model.predict_classes(X_test_pp))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 - 4s - loss: 1.8878 - accuracy: 0.2466 - val_loss: 1.6690 - val_accuracy: 0.4380\n",
            "Epoch 2/50\n",
            "6/6 - 3s - loss: 1.6925 - accuracy: 0.4049 - val_loss: 1.6290 - val_accuracy: 0.4380\n",
            "Epoch 3/50\n",
            "6/6 - 3s - loss: 1.6793 - accuracy: 0.4049 - val_loss: 1.6076 - val_accuracy: 0.4380\n",
            "Epoch 4/50\n",
            "6/6 - 3s - loss: 1.6634 - accuracy: 0.4078 - val_loss: 1.6036 - val_accuracy: 0.4380\n",
            "Epoch 5/50\n",
            "6/6 - 3s - loss: 1.6442 - accuracy: 0.4049 - val_loss: 1.5726 - val_accuracy: 0.4457\n",
            "Epoch 6/50\n",
            "6/6 - 3s - loss: 1.6028 - accuracy: 0.4320 - val_loss: 1.5216 - val_accuracy: 0.4457\n",
            "Epoch 7/50\n",
            "6/6 - 3s - loss: 1.5283 - accuracy: 0.4650 - val_loss: 1.4899 - val_accuracy: 0.4457\n",
            "Epoch 8/50\n",
            "6/6 - 3s - loss: 1.4588 - accuracy: 0.4689 - val_loss: 1.4516 - val_accuracy: 0.4651\n",
            "Epoch 9/50\n",
            "6/6 - 3s - loss: 1.3512 - accuracy: 0.5136 - val_loss: 1.3183 - val_accuracy: 0.5310\n",
            "Epoch 10/50\n",
            "6/6 - 3s - loss: 1.2703 - accuracy: 0.5398 - val_loss: 1.2365 - val_accuracy: 0.5853\n",
            "Epoch 11/50\n",
            "6/6 - 3s - loss: 1.1647 - accuracy: 0.5816 - val_loss: 1.1775 - val_accuracy: 0.6279\n",
            "Epoch 12/50\n",
            "6/6 - 3s - loss: 1.0639 - accuracy: 0.6194 - val_loss: 1.0975 - val_accuracy: 0.6628\n",
            "Epoch 13/50\n",
            "6/6 - 3s - loss: 0.9679 - accuracy: 0.6864 - val_loss: 1.0200 - val_accuracy: 0.6202\n",
            "Epoch 14/50\n",
            "6/6 - 3s - loss: 0.9124 - accuracy: 0.6942 - val_loss: 0.9194 - val_accuracy: 0.6899\n",
            "Epoch 15/50\n",
            "6/6 - 3s - loss: 0.8276 - accuracy: 0.7146 - val_loss: 0.8671 - val_accuracy: 0.7209\n",
            "Epoch 16/50\n",
            "6/6 - 3s - loss: 0.7693 - accuracy: 0.7330 - val_loss: 1.0844 - val_accuracy: 0.6124\n",
            "Epoch 17/50\n",
            "6/6 - 3s - loss: 0.8079 - accuracy: 0.7214 - val_loss: 0.8635 - val_accuracy: 0.7326\n",
            "Epoch 18/50\n",
            "6/6 - 3s - loss: 0.7351 - accuracy: 0.7485 - val_loss: 0.8351 - val_accuracy: 0.7287\n",
            "Epoch 19/50\n",
            "6/6 - 3s - loss: 0.6882 - accuracy: 0.7825 - val_loss: 0.7991 - val_accuracy: 0.7442\n",
            "Epoch 20/50\n",
            "6/6 - 3s - loss: 0.6294 - accuracy: 0.7922 - val_loss: 0.8024 - val_accuracy: 0.7132\n",
            "Epoch 21/50\n",
            "6/6 - 3s - loss: 0.6075 - accuracy: 0.7942 - val_loss: 0.7779 - val_accuracy: 0.7364\n",
            "Epoch 22/50\n",
            "6/6 - 3s - loss: 0.6017 - accuracy: 0.7961 - val_loss: 0.8035 - val_accuracy: 0.7481\n",
            "Epoch 23/50\n",
            "6/6 - 3s - loss: 0.6045 - accuracy: 0.8000 - val_loss: 0.7780 - val_accuracy: 0.7636\n",
            "Epoch 24/50\n",
            "6/6 - 3s - loss: 0.5564 - accuracy: 0.8214 - val_loss: 0.7587 - val_accuracy: 0.7403\n",
            "Epoch 25/50\n",
            "6/6 - 3s - loss: 0.5105 - accuracy: 0.8320 - val_loss: 0.7399 - val_accuracy: 0.7674\n",
            "Epoch 26/50\n",
            "6/6 - 3s - loss: 0.4918 - accuracy: 0.8262 - val_loss: 0.8145 - val_accuracy: 0.7248\n",
            "Epoch 27/50\n",
            "6/6 - 3s - loss: 0.5290 - accuracy: 0.8126 - val_loss: 0.7105 - val_accuracy: 0.7713\n",
            "Epoch 28/50\n",
            "6/6 - 3s - loss: 0.4374 - accuracy: 0.8621 - val_loss: 0.6937 - val_accuracy: 0.7636\n",
            "Epoch 29/50\n",
            "6/6 - 3s - loss: 0.4301 - accuracy: 0.8583 - val_loss: 0.6803 - val_accuracy: 0.7752\n",
            "Epoch 30/50\n",
            "6/6 - 3s - loss: 0.3940 - accuracy: 0.8621 - val_loss: 0.6695 - val_accuracy: 0.7752\n",
            "Epoch 31/50\n",
            "6/6 - 3s - loss: 0.3802 - accuracy: 0.8738 - val_loss: 0.6722 - val_accuracy: 0.7674\n",
            "Epoch 32/50\n",
            "6/6 - 3s - loss: 0.3698 - accuracy: 0.8854 - val_loss: 0.6563 - val_accuracy: 0.7907\n",
            "Epoch 33/50\n",
            "6/6 - 3s - loss: 0.3570 - accuracy: 0.8854 - val_loss: 0.6582 - val_accuracy: 0.7829\n",
            "Epoch 34/50\n",
            "6/6 - 3s - loss: 0.3588 - accuracy: 0.8845 - val_loss: 0.6026 - val_accuracy: 0.7984\n",
            "Epoch 35/50\n",
            "6/6 - 3s - loss: 0.3068 - accuracy: 0.9097 - val_loss: 0.6239 - val_accuracy: 0.7984\n",
            "Epoch 36/50\n",
            "6/6 - 3s - loss: 0.2986 - accuracy: 0.9058 - val_loss: 0.6063 - val_accuracy: 0.8101\n",
            "Epoch 37/50\n",
            "6/6 - 3s - loss: 0.2891 - accuracy: 0.9223 - val_loss: 0.6173 - val_accuracy: 0.7984\n",
            "Epoch 38/50\n",
            "6/6 - 3s - loss: 0.2648 - accuracy: 0.9194 - val_loss: 0.6248 - val_accuracy: 0.7946\n",
            "Epoch 39/50\n",
            "6/6 - 3s - loss: 0.2589 - accuracy: 0.9223 - val_loss: 0.5938 - val_accuracy: 0.8023\n",
            "Epoch 40/50\n",
            "6/6 - 3s - loss: 0.2358 - accuracy: 0.9262 - val_loss: 0.6006 - val_accuracy: 0.8023\n",
            "Epoch 41/50\n",
            "6/6 - 3s - loss: 0.2242 - accuracy: 0.9340 - val_loss: 0.5862 - val_accuracy: 0.8023\n",
            "Epoch 42/50\n",
            "6/6 - 3s - loss: 0.2171 - accuracy: 0.9350 - val_loss: 0.5825 - val_accuracy: 0.8178\n",
            "Epoch 43/50\n",
            "6/6 - 3s - loss: 0.2030 - accuracy: 0.9408 - val_loss: 0.6458 - val_accuracy: 0.8101\n",
            "Epoch 44/50\n",
            "6/6 - 3s - loss: 0.2106 - accuracy: 0.9340 - val_loss: 0.5887 - val_accuracy: 0.8062\n",
            "Epoch 45/50\n",
            "6/6 - 3s - loss: 0.1877 - accuracy: 0.9417 - val_loss: 0.5608 - val_accuracy: 0.8256\n",
            "Epoch 46/50\n",
            "6/6 - 3s - loss: 0.1636 - accuracy: 0.9515 - val_loss: 0.5953 - val_accuracy: 0.8178\n",
            "Epoch 47/50\n",
            "6/6 - 3s - loss: 0.1806 - accuracy: 0.9485 - val_loss: 0.6040 - val_accuracy: 0.8101\n",
            "Epoch 48/50\n",
            "6/6 - 3s - loss: 0.1769 - accuracy: 0.9505 - val_loss: 0.5652 - val_accuracy: 0.8101\n",
            "Epoch 49/50\n",
            "6/6 - 3s - loss: 0.1591 - accuracy: 0.9534 - val_loss: 0.5685 - val_accuracy: 0.8178\n",
            "Epoch 50/50\n",
            "6/6 - 3s - loss: 0.1410 - accuracy: 0.9563 - val_loss: 0.5656 - val_accuracy: 0.8140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.813953488372093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtEyCeX2OwUD",
        "outputId": "89c0f0c6-f9ec-4586-cbba-9a90bb8bd385"
      },
      "source": [
        "\n",
        "# model convolution window 3x3\n",
        "\n",
        "np.random.seed(2002)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile, fit, and generate scores and predicted probabilities.\n",
        "# should take under 2-3 minutes to train\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_pp, y_train_pp, validation_data=(X_test_pp, y_test_pp), epochs=50, batch_size=200, verbose=2)\n",
        "scores = model.evaluate(X_test_pp, y_test_pp, verbose=0)\n",
        "prob = model.predict(X_test_pp)\n",
        "\n",
        "accuracy_score(y_test, model.predict_classes(X_test_pp))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 - 3s - loss: 1.9877 - accuracy: 0.2301 - val_loss: 1.7606 - val_accuracy: 0.4380\n",
            "Epoch 2/50\n",
            "6/6 - 2s - loss: 1.7353 - accuracy: 0.4049 - val_loss: 1.6429 - val_accuracy: 0.4380\n",
            "Epoch 3/50\n",
            "6/6 - 2s - loss: 1.6864 - accuracy: 0.4049 - val_loss: 1.6133 - val_accuracy: 0.4380\n",
            "Epoch 4/50\n",
            "6/6 - 2s - loss: 1.6697 - accuracy: 0.4049 - val_loss: 1.5975 - val_accuracy: 0.4380\n",
            "Epoch 5/50\n",
            "6/6 - 2s - loss: 1.6476 - accuracy: 0.4049 - val_loss: 1.5605 - val_accuracy: 0.4380\n",
            "Epoch 6/50\n",
            "6/6 - 2s - loss: 1.5888 - accuracy: 0.4146 - val_loss: 1.5444 - val_accuracy: 0.5233\n",
            "Epoch 7/50\n",
            "6/6 - 2s - loss: 1.5148 - accuracy: 0.4456 - val_loss: 1.4938 - val_accuracy: 0.5271\n",
            "Epoch 8/50\n",
            "6/6 - 2s - loss: 1.4199 - accuracy: 0.4825 - val_loss: 1.6316 - val_accuracy: 0.3101\n",
            "Epoch 9/50\n",
            "6/6 - 2s - loss: 1.4559 - accuracy: 0.4311 - val_loss: 1.4172 - val_accuracy: 0.4767\n",
            "Epoch 10/50\n",
            "6/6 - 2s - loss: 1.3020 - accuracy: 0.5068 - val_loss: 1.3121 - val_accuracy: 0.5349\n",
            "Epoch 11/50\n",
            "6/6 - 2s - loss: 1.1943 - accuracy: 0.5515 - val_loss: 1.1707 - val_accuracy: 0.6047\n",
            "Epoch 12/50\n",
            "6/6 - 2s - loss: 1.0858 - accuracy: 0.5932 - val_loss: 1.1137 - val_accuracy: 0.6318\n",
            "Epoch 13/50\n",
            "6/6 - 2s - loss: 0.9605 - accuracy: 0.6456 - val_loss: 1.0068 - val_accuracy: 0.6860\n",
            "Epoch 14/50\n",
            "6/6 - 2s - loss: 0.8630 - accuracy: 0.6942 - val_loss: 0.9180 - val_accuracy: 0.7171\n",
            "Epoch 15/50\n",
            "6/6 - 2s - loss: 0.7623 - accuracy: 0.7466 - val_loss: 0.8764 - val_accuracy: 0.6938\n",
            "Epoch 16/50\n",
            "6/6 - 2s - loss: 0.6781 - accuracy: 0.7845 - val_loss: 0.7783 - val_accuracy: 0.7597\n",
            "Epoch 17/50\n",
            "6/6 - 2s - loss: 0.6008 - accuracy: 0.8214 - val_loss: 0.8197 - val_accuracy: 0.7326\n",
            "Epoch 18/50\n",
            "6/6 - 2s - loss: 0.5663 - accuracy: 0.8165 - val_loss: 0.7895 - val_accuracy: 0.7597\n",
            "Epoch 19/50\n",
            "6/6 - 2s - loss: 0.5347 - accuracy: 0.8350 - val_loss: 0.6926 - val_accuracy: 0.7481\n",
            "Epoch 20/50\n",
            "6/6 - 2s - loss: 0.5046 - accuracy: 0.8417 - val_loss: 0.7029 - val_accuracy: 0.7636\n",
            "Epoch 21/50\n",
            "6/6 - 2s - loss: 0.4813 - accuracy: 0.8456 - val_loss: 0.7052 - val_accuracy: 0.7442\n",
            "Epoch 22/50\n",
            "6/6 - 2s - loss: 0.4278 - accuracy: 0.8670 - val_loss: 0.6345 - val_accuracy: 0.7907\n",
            "Epoch 23/50\n",
            "6/6 - 2s - loss: 0.3920 - accuracy: 0.8845 - val_loss: 0.5914 - val_accuracy: 0.8062\n",
            "Epoch 24/50\n",
            "6/6 - 2s - loss: 0.3729 - accuracy: 0.8942 - val_loss: 0.5477 - val_accuracy: 0.8295\n",
            "Epoch 25/50\n",
            "6/6 - 2s - loss: 0.3376 - accuracy: 0.8990 - val_loss: 0.5801 - val_accuracy: 0.8140\n",
            "Epoch 26/50\n",
            "6/6 - 2s - loss: 0.3200 - accuracy: 0.9087 - val_loss: 0.6322 - val_accuracy: 0.7752\n",
            "Epoch 27/50\n",
            "6/6 - 2s - loss: 0.3064 - accuracy: 0.9029 - val_loss: 0.5688 - val_accuracy: 0.8295\n",
            "Epoch 28/50\n",
            "6/6 - 2s - loss: 0.2866 - accuracy: 0.9165 - val_loss: 0.5384 - val_accuracy: 0.8062\n",
            "Epoch 29/50\n",
            "6/6 - 2s - loss: 0.2512 - accuracy: 0.9282 - val_loss: 0.5836 - val_accuracy: 0.8178\n",
            "Epoch 30/50\n",
            "6/6 - 2s - loss: 0.2317 - accuracy: 0.9301 - val_loss: 0.5577 - val_accuracy: 0.8101\n",
            "Epoch 31/50\n",
            "6/6 - 3s - loss: 0.2266 - accuracy: 0.9350 - val_loss: 0.5831 - val_accuracy: 0.8178\n",
            "Epoch 32/50\n",
            "6/6 - 2s - loss: 0.2564 - accuracy: 0.9214 - val_loss: 0.6264 - val_accuracy: 0.7946\n",
            "Epoch 33/50\n",
            "6/6 - 2s - loss: 0.2223 - accuracy: 0.9340 - val_loss: 0.5315 - val_accuracy: 0.8295\n",
            "Epoch 34/50\n",
            "6/6 - 2s - loss: 0.1978 - accuracy: 0.9447 - val_loss: 0.5540 - val_accuracy: 0.8217\n",
            "Epoch 35/50\n",
            "6/6 - 2s - loss: 0.1859 - accuracy: 0.9456 - val_loss: 0.5544 - val_accuracy: 0.8178\n",
            "Epoch 36/50\n",
            "6/6 - 2s - loss: 0.1834 - accuracy: 0.9534 - val_loss: 0.5263 - val_accuracy: 0.8295\n",
            "Epoch 37/50\n",
            "6/6 - 2s - loss: 0.1530 - accuracy: 0.9592 - val_loss: 0.5198 - val_accuracy: 0.8488\n",
            "Epoch 38/50\n",
            "6/6 - 2s - loss: 0.1361 - accuracy: 0.9612 - val_loss: 0.5754 - val_accuracy: 0.8217\n",
            "Epoch 39/50\n",
            "6/6 - 2s - loss: 0.1565 - accuracy: 0.9553 - val_loss: 0.5592 - val_accuracy: 0.8256\n",
            "Epoch 40/50\n",
            "6/6 - 2s - loss: 0.1591 - accuracy: 0.9563 - val_loss: 0.5724 - val_accuracy: 0.8178\n",
            "Epoch 41/50\n",
            "6/6 - 2s - loss: 0.1196 - accuracy: 0.9718 - val_loss: 0.5363 - val_accuracy: 0.8372\n",
            "Epoch 42/50\n",
            "6/6 - 2s - loss: 0.1132 - accuracy: 0.9786 - val_loss: 0.5306 - val_accuracy: 0.8411\n",
            "Epoch 43/50\n",
            "6/6 - 2s - loss: 0.1035 - accuracy: 0.9767 - val_loss: 0.5352 - val_accuracy: 0.8450\n",
            "Epoch 44/50\n",
            "6/6 - 2s - loss: 0.0981 - accuracy: 0.9816 - val_loss: 0.5243 - val_accuracy: 0.8295\n",
            "Epoch 45/50\n",
            "6/6 - 2s - loss: 0.0812 - accuracy: 0.9816 - val_loss: 0.5036 - val_accuracy: 0.8527\n",
            "Epoch 46/50\n",
            "6/6 - 2s - loss: 0.0718 - accuracy: 0.9874 - val_loss: 0.5126 - val_accuracy: 0.8411\n",
            "Epoch 47/50\n",
            "6/6 - 2s - loss: 0.0677 - accuracy: 0.9883 - val_loss: 0.5178 - val_accuracy: 0.8372\n",
            "Epoch 48/50\n",
            "6/6 - 2s - loss: 0.0692 - accuracy: 0.9845 - val_loss: 0.5632 - val_accuracy: 0.8450\n",
            "Epoch 49/50\n",
            "6/6 - 2s - loss: 0.0643 - accuracy: 0.9893 - val_loss: 0.5442 - val_accuracy: 0.8372\n",
            "Epoch 50/50\n",
            "6/6 - 2s - loss: 0.0587 - accuracy: 0.9883 - val_loss: 0.5442 - val_accuracy: 0.8450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8449612403100775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KKDkdB0PAwq",
        "outputId": "62b81beb-f80e-4e82-c52d-0210db90e87d"
      },
      "source": [
        "\n",
        "# model convolution window 10 x 10\n",
        "\n",
        "np.random.seed(2002)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (10, 10), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (10, 10), input_shape=(50, 37, 1), activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile, fit, and generate scores and predicted probabilities.\n",
        "# should take under 2-3 minutes to train\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_pp, y_train_pp, validation_data=(X_test_pp, y_test_pp), epochs=50, batch_size=200, verbose=2)\n",
        "scores = model.evaluate(X_test_pp, y_test_pp, verbose=0)\n",
        "prob = model.predict(X_test_pp)\n",
        "\n",
        "accuracy_score(y_test, model.predict_classes(X_test_pp))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 - 4s - loss: 1.9162 - accuracy: 0.2621 - val_loss: 1.7830 - val_accuracy: 0.4380\n",
            "Epoch 2/50\n",
            "6/6 - 4s - loss: 1.7699 - accuracy: 0.4049 - val_loss: 1.6640 - val_accuracy: 0.4380\n",
            "Epoch 3/50\n",
            "6/6 - 4s - loss: 1.7258 - accuracy: 0.4049 - val_loss: 1.6293 - val_accuracy: 0.4380\n",
            "Epoch 4/50\n",
            "6/6 - 4s - loss: 1.7119 - accuracy: 0.4049 - val_loss: 1.6676 - val_accuracy: 0.4380\n",
            "Epoch 5/50\n",
            "6/6 - 4s - loss: 1.6993 - accuracy: 0.4049 - val_loss: 1.6318 - val_accuracy: 0.4380\n",
            "Epoch 6/50\n",
            "6/6 - 4s - loss: 1.6912 - accuracy: 0.4049 - val_loss: 1.6452 - val_accuracy: 0.4380\n",
            "Epoch 7/50\n",
            "6/6 - 4s - loss: 1.6819 - accuracy: 0.4049 - val_loss: 1.6076 - val_accuracy: 0.4380\n",
            "Epoch 8/50\n",
            "6/6 - 4s - loss: 1.6795 - accuracy: 0.4049 - val_loss: 1.6277 - val_accuracy: 0.4380\n",
            "Epoch 9/50\n",
            "6/6 - 4s - loss: 1.6647 - accuracy: 0.4049 - val_loss: 1.6011 - val_accuracy: 0.4380\n",
            "Epoch 10/50\n",
            "6/6 - 4s - loss: 1.6493 - accuracy: 0.4049 - val_loss: 1.5775 - val_accuracy: 0.4380\n",
            "Epoch 11/50\n",
            "6/6 - 4s - loss: 1.6353 - accuracy: 0.4087 - val_loss: 1.5775 - val_accuracy: 0.4419\n",
            "Epoch 12/50\n",
            "6/6 - 4s - loss: 1.5997 - accuracy: 0.4078 - val_loss: 1.5301 - val_accuracy: 0.4457\n",
            "Epoch 13/50\n",
            "6/6 - 4s - loss: 1.5573 - accuracy: 0.4388 - val_loss: 1.5227 - val_accuracy: 0.4961\n",
            "Epoch 14/50\n",
            "6/6 - 4s - loss: 1.5317 - accuracy: 0.4534 - val_loss: 1.6901 - val_accuracy: 0.3256\n",
            "Epoch 15/50\n",
            "6/6 - 4s - loss: 1.5751 - accuracy: 0.4320 - val_loss: 1.4909 - val_accuracy: 0.5155\n",
            "Epoch 16/50\n",
            "6/6 - 4s - loss: 1.4816 - accuracy: 0.4699 - val_loss: 1.4552 - val_accuracy: 0.5155\n",
            "Epoch 17/50\n",
            "6/6 - 4s - loss: 1.4547 - accuracy: 0.4767 - val_loss: 1.4341 - val_accuracy: 0.5155\n",
            "Epoch 18/50\n",
            "6/6 - 4s - loss: 1.4020 - accuracy: 0.4893 - val_loss: 1.3825 - val_accuracy: 0.5426\n",
            "Epoch 19/50\n",
            "6/6 - 4s - loss: 1.3789 - accuracy: 0.5039 - val_loss: 1.3569 - val_accuracy: 0.5194\n",
            "Epoch 20/50\n",
            "6/6 - 4s - loss: 1.3439 - accuracy: 0.5097 - val_loss: 1.2879 - val_accuracy: 0.5659\n",
            "Epoch 21/50\n",
            "6/6 - 4s - loss: 1.2840 - accuracy: 0.5350 - val_loss: 1.2485 - val_accuracy: 0.5969\n",
            "Epoch 22/50\n",
            "6/6 - 4s - loss: 1.2657 - accuracy: 0.5583 - val_loss: 1.3440 - val_accuracy: 0.5155\n",
            "Epoch 23/50\n",
            "6/6 - 4s - loss: 1.3216 - accuracy: 0.5282 - val_loss: 1.2436 - val_accuracy: 0.5659\n",
            "Epoch 24/50\n",
            "6/6 - 4s - loss: 1.1816 - accuracy: 0.5670 - val_loss: 1.1870 - val_accuracy: 0.5930\n",
            "Epoch 25/50\n",
            "6/6 - 4s - loss: 1.1443 - accuracy: 0.5854 - val_loss: 1.1106 - val_accuracy: 0.6473\n",
            "Epoch 26/50\n",
            "6/6 - 4s - loss: 1.1113 - accuracy: 0.6136 - val_loss: 1.0924 - val_accuracy: 0.6085\n",
            "Epoch 27/50\n",
            "6/6 - 4s - loss: 1.1000 - accuracy: 0.5942 - val_loss: 1.0547 - val_accuracy: 0.6434\n",
            "Epoch 28/50\n",
            "6/6 - 4s - loss: 1.0360 - accuracy: 0.6398 - val_loss: 1.0350 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "6/6 - 4s - loss: 0.9907 - accuracy: 0.6476 - val_loss: 1.0040 - val_accuracy: 0.6783\n",
            "Epoch 30/50\n",
            "6/6 - 4s - loss: 0.9433 - accuracy: 0.6854 - val_loss: 1.0053 - val_accuracy: 0.6628\n",
            "Epoch 31/50\n",
            "6/6 - 4s - loss: 0.9307 - accuracy: 0.6728 - val_loss: 0.9988 - val_accuracy: 0.6589\n",
            "Epoch 32/50\n",
            "6/6 - 4s - loss: 0.9170 - accuracy: 0.6874 - val_loss: 0.9513 - val_accuracy: 0.6822\n",
            "Epoch 33/50\n",
            "6/6 - 4s - loss: 0.8893 - accuracy: 0.6932 - val_loss: 0.9892 - val_accuracy: 0.6473\n",
            "Epoch 34/50\n",
            "6/6 - 4s - loss: 0.8693 - accuracy: 0.7175 - val_loss: 0.8920 - val_accuracy: 0.7093\n",
            "Epoch 35/50\n",
            "6/6 - 4s - loss: 0.8344 - accuracy: 0.7301 - val_loss: 0.9325 - val_accuracy: 0.7171\n",
            "Epoch 36/50\n",
            "6/6 - 4s - loss: 0.8107 - accuracy: 0.7223 - val_loss: 0.8801 - val_accuracy: 0.7132\n",
            "Epoch 37/50\n",
            "6/6 - 4s - loss: 0.7769 - accuracy: 0.7291 - val_loss: 0.8727 - val_accuracy: 0.6977\n",
            "Epoch 38/50\n",
            "6/6 - 4s - loss: 0.7826 - accuracy: 0.7369 - val_loss: 0.8474 - val_accuracy: 0.7016\n",
            "Epoch 39/50\n",
            "6/6 - 4s - loss: 0.7275 - accuracy: 0.7621 - val_loss: 0.8650 - val_accuracy: 0.7016\n",
            "Epoch 40/50\n",
            "6/6 - 4s - loss: 0.7007 - accuracy: 0.7563 - val_loss: 0.7783 - val_accuracy: 0.7442\n",
            "Epoch 41/50\n",
            "6/6 - 4s - loss: 0.6573 - accuracy: 0.7864 - val_loss: 0.7775 - val_accuracy: 0.7287\n",
            "Epoch 42/50\n",
            "6/6 - 4s - loss: 0.6470 - accuracy: 0.7757 - val_loss: 0.7941 - val_accuracy: 0.7248\n",
            "Epoch 43/50\n",
            "6/6 - 4s - loss: 0.7041 - accuracy: 0.7515 - val_loss: 0.8694 - val_accuracy: 0.6822\n",
            "Epoch 44/50\n",
            "6/6 - 4s - loss: 0.7045 - accuracy: 0.7650 - val_loss: 0.7885 - val_accuracy: 0.7287\n",
            "Epoch 45/50\n",
            "6/6 - 4s - loss: 0.6333 - accuracy: 0.7913 - val_loss: 0.7929 - val_accuracy: 0.7442\n",
            "Epoch 46/50\n",
            "6/6 - 4s - loss: 0.6071 - accuracy: 0.8049 - val_loss: 0.7661 - val_accuracy: 0.7481\n",
            "Epoch 47/50\n",
            "6/6 - 4s - loss: 0.5884 - accuracy: 0.8058 - val_loss: 0.7850 - val_accuracy: 0.7442\n",
            "Epoch 48/50\n",
            "6/6 - 4s - loss: 0.6180 - accuracy: 0.7806 - val_loss: 0.7409 - val_accuracy: 0.7519\n",
            "Epoch 49/50\n",
            "6/6 - 4s - loss: 0.5644 - accuracy: 0.8087 - val_loss: 0.7344 - val_accuracy: 0.7636\n",
            "Epoch 50/50\n",
            "6/6 - 4s - loss: 0.5381 - accuracy: 0.8204 - val_loss: 0.7350 - val_accuracy: 0.7597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7596899224806202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWewow-XvvfD"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "1. Try different word count in the next-word prediction task with a)8 and b)12 previous words and report accuracy for each. Use the same Sherlock data.\n",
        "\n",
        "2. Try different LSTM architectures and comment on model performace for each. \n",
        "    - Add a dropout layer with 0.25\n",
        "    - Change number of neurons to a) 64 b) 256 neurons\n",
        "    \n",
        "    Train for 10 epochs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BweVsntVvvfE",
        "outputId": "f713f963-608d-4a52-97b7-137228b4fca0"
      },
      "source": [
        "path = 'sherlock.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 581889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS6NWMfCvvfE"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words = tokenizer.tokenize(text)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0tO_xOxVz19"
      },
      "source": [
        "# unique sorted words list\n",
        "unique_words = np.unique(words)\n",
        "\n",
        "# dictionary(<key: value>) with each word form the unique_words list as key and its corresponding position as value.\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfsFM-q3V3cK",
        "outputId": "c0e2751a-2117-4510-d93b-a5b10b2a1415"
      },
      "source": [
        "#With 8 previous words\n",
        "\n",
        "WORD_LENGTH = 8\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])\n",
        "    next_words.append(words[i + WORD_LENGTH])\n",
        "print('sequence:', prev_words[10101])\n",
        "print('next word in sequence:', next_words[10101])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequence: ['of', 'twenty', 'one', 'years', 'are', 'eligible', 'apply', 'in']\n",
            "next word in sequence: person\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFsEAz-gV_6k"
      },
      "source": [
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSLdTU3oWE9e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeupdwYwWRi5",
        "outputId": "0f26588e-3d84-48d9-968c-709ae78f1f87"
      },
      "source": [
        "\n",
        "# training - just 2 epochs - should take around 5-7 mins for 2 epochs\n",
        "\n",
        "np.random.seed(2002)\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "811/811 [==============================] - 370s 453ms/step - loss: 6.3230 - accuracy: 0.0838 - val_loss: 7.1331 - val_accuracy: 0.1053\n",
            "Epoch 2/2\n",
            "811/811 [==============================] - 366s 451ms/step - loss: 5.6483 - accuracy: 0.1448 - val_loss: 7.9011 - val_accuracy: 0.1058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9RVpWrWWTRF"
      },
      "source": [
        "# function for preparing input as vecotrs\n",
        "\n",
        "def prepare_input(text):\n",
        "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
        "    for t, word in enumerate(text.split()):\n",
        "        print(word)\n",
        "        x[0, t, unique_word_index[word]] = 1\n",
        "    return x\n",
        "\n",
        "# function for n choose best possible words after prediction\n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
        "\n",
        "# for prediction\n",
        "def predict_completions(text, n=3):\n",
        "    if text == \"\":\n",
        "        return(\"0\")\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [unique_words[idx] for idx in next_indices]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "xxmRrsRsWjqG",
        "outputId": "9ebd2871-35e6-48f1-9faa-b58ef8130549"
      },
      "source": [
        "\n",
        "# probabilities for predicted words\n",
        "q =  \"Your life will never be the same again\"\n",
        "\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:8])\n",
        "\n",
        "prob = model.predict(prepare_input(seq), verbose=0)[0] # calculate probabilities\n",
        "[prob[key] for key in np.argsort(prob)[-5:][::-1]]  # print for predicted words"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your\n",
            "life\n",
            "will\n",
            "never\n",
            "be\n",
            "the\n",
            "same\n",
            "again\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-fb66f2f8f850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# calculate probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# print for predicted words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_21 is incompatible with the layer: expected axis -1 of input shape to have value 100 but received input with shape (None, 8, 8201)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCK9XKo3YYcQ"
      },
      "source": [
        "#Now with 12 previous words\n",
        "WORD_LENGTH = 12\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])\n",
        "    next_words.append(words[i + WORD_LENGTH])\n",
        "print('sequence:', prev_words[10101])\n",
        "print('next word in sequence:', next_words[10101])\n",
        "\n",
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_YWCnx9YajU"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDj3SXasYl6i"
      },
      "source": [
        "\n",
        "# training - just 2 epochs - should take around 5-7 mins for 2 epochs\n",
        "\n",
        "np.random.seed(2002)\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq5hNFSKYpK-"
      },
      "source": [
        "\n",
        "# probabilities for predicted words\n",
        "\n",
        "prob = model.predict(prepare_input(seq), verbose=0)[0] # calculate probabilities\n",
        "[prob[key] for key in np.argsort(prob)[-5:][::-1]]  # print for predicted words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6wr2cOQp3dy"
      },
      "source": [
        "# With dropout layer .25\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# training - just 2 epochs - should take around 5-7 mins for 2 epochs\n",
        "\n",
        "np.random.seed(2002)\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history\n",
        "\n",
        "\n",
        "# probabilities for predicted words\n",
        "\n",
        "prob = model.predict(prepare_input(seq), verbose=0)[0] # calculate probabilities\n",
        "[prob[key] for key in np.argsort(prob)[-5:][::-1]]  # print for predicted words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1LhehFdqCFQ"
      },
      "source": [
        "# With 64 neurons\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# training - just 2 epochs - should take around 5-7 mins for 2 epochs\n",
        "\n",
        "np.random.seed(2002)\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history\n",
        "\n",
        "\n",
        "# probabilities for predicted words\n",
        "\n",
        "prob = model.predict(prepare_input(seq), verbose=0)[0] # calculate probabilities\n",
        "[prob[key] for key in np.argsort(prob)[-5:][::-1]]  # print for predicted words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqw1T5t-qJdm"
      },
      "source": [
        "# With 256 neurons\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# training - just 2 epochs - should take around 5-7 mins for 2 epochs\n",
        "\n",
        "np.random.seed(2002)\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history\n",
        "\n",
        "\n",
        "# probabilities for predicted words\n",
        "\n",
        "prob = model.predict(prepare_input(seq), verbose=0)[0] # calculate probabilities\n",
        "[prob[key] for key in np.argsort(prob)[-5:][::-1]]  # print for predicted words"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}